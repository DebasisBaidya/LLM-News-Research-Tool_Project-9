# âœ… Phase 1: Environment Setup (Completed)
# -----------------------------------------------------
# ğŸ“Œ Task 1.1: Install Required Libraries
# - Iâ€™m installing the essential Python libraries to handle LLM logic, UI, and news scraping.
# - The required libraries are: langchain, streamlit, newsapi-python, groq, and python-dotenv

# âœ… Installation Command:
# pip install langchain streamlit newsapi-python groq python-dotenv

# ğŸ“Œ Task 1.2: Obtain API Keys
# - Iâ€™m generating the required API keys to access Groqâ€™s LLM and NewsAPI.
# - Getting Groq API key from: https://console.groq.com/keys
# - Getting NewsAPI key from: https://newsapi.org/

# ğŸ“Œ Task 1.3: Stored in 'Streamlit Secret TOML' file

# âœ… Phase 1 â†’ Phase 3: Environment Setup + LangChain + Summarization Logic

import os
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from newsapi import NewsApiClient

# ğŸ“Œ Task 1.1: Load Environment Variables
# ğŸ” Load API keys securely from .env or Streamlit Secrets
load_dotenv()
groq_api_key = os.getenv("GROQ_API_KEY")
news_api_key = os.getenv("NEWS_API_KEY")

# ğŸ“Œ Task 2.1: Initialize the Language Model
# ğŸ§  Connecting to Groq's LLaMA3 model
llm = ChatGroq(groq_api_key=groq_api_key, model_name="llama3-70b-8192")

# ğŸ“Œ Task 3.1: Design Prompt Template
# âœï¸ This prompt ensures clear, fact-based summaries without fluff
enhanced_template = """
You are an intelligent and strictly factual AI news summarizer.

Given a user query and a set of real-time news article excerpts,
generate an accurate, concise summary of the situation.

âœ… Summary Guidelines:
â€¢ Be strictly factual and free of bias
â€¢ Cover key developments and details
â€¢ Provide 4 to 6 bullet points only
â€¢ Use the â€¢ bullet symbol consistently
â€¢ Avoid restating the query or adding an intro/outro
â€¢ NEVER invent or speculate â€” rely strictly on article data

---

ğŸ“ User Query:
{query}

ğŸ“° News Article Content:
{summaries}

---

ğŸ“Œ Provide only the final bullet-point summary below:
"""

# ğŸ“Œ Task 3.1.2: Compile Prompt Template
prompt = PromptTemplate(template=enhanced_template, input_variables=["query", "summaries"])

# ğŸ”— Create LLMChain with model and prompt
llm_chain = LLMChain(prompt=prompt, llm=llm)

# ğŸ“Œ Task 3.2: Setup NewsAPI
# ğŸŒ Fetch news articles via keyword search
newsapi = NewsApiClient(api_key=news_api_key)

def get_news_articles(query):
    articles = newsapi.get_everything(q=query, language='en', sort_by='publishedAt', page_size=10)
    return articles.get("articles", [])

# ğŸ“Œ Task 3.2.1: Combine article content into a string
# ğŸ§¾ Extract description or content from each article
def summarize_articles(articles):
    return ' '.join(
        article.get('description') or article.get('content') or ''
        for article in articles
    )

# ğŸ“Œ Task 3.3: Summarization Entry Point
# ğŸ§  Return a summary and metadata for use in the UI
def get_summary(query):
    articles = get_news_articles(query)
    summaries = summarize_articles(articles)

    if not summaries.strip():
        return "âš ï¸ No content found to summarize. Try another topic.", []

    used_articles = [a for a in articles if a.get('description') or a.get('content')]
    summary_output = llm_chain.run(query=query, summaries=summaries)

    return summary_output, used_articles



# âœ… Outcome:
# Iâ€™ve now fully connected LangChain to Groqâ€™s LLM and NewsAPI.
# My tool can now fetch and summarize real-time news on any topic â€” politics, tech, finance, sports, and more â€”
# using smart prompt templates and chains for accurate, readable summaries.
