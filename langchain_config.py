# âœ… Phase 1: Environment Setup (Completed)
# -----------------------------------------------------
# ğŸ“Œ Task 1.1: Install Required Libraries
# - Iâ€™m installing the essential Python libraries to handle LLM logic, UI, and news scraping.
# - The required libraries are: langchain, streamlit, newsapi-python, groq, and python-dotenv

# âœ… Installation Command:
# pip install langchain streamlit newsapi-python groq python-dotenv

# ğŸ“Œ Task 1.2: Obtain API Keys
# - Iâ€™m generating the required API keys to access Groqâ€™s LLM and NewsAPI.
# - Getting Groq API key from: https://console.groq.com/keys
# - Getting NewsAPI key from: https://newsapi.org/

# ğŸ“Œ Task 1.3: is in 'Streamlit Secret TOML' file

# âœ… Phase 2: LangChain Configuration using Groq API
# ----------------------------------------------------

import os
import streamlit as st
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from newsapi import NewsApiClient

# âœ… Loading environment variables from .env file
#load_dotenv()

# âœ… Access secrets via st.secrets or os.environ
groq_api_key = st.secrets["GROQ_API_KEY"]
news_api_key = st.secrets["NEWS_API_KEY"]

# âœ… Initializing Groq-based LLM
# Iâ€™m connecting to Groq's LLaMA3 model (powerful, fast, free to use)
llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name="llama3-70b-8192")

# âœ… ğŸ§  Prompt Template with Crisp Bullet Output
initial_template = """
ğŸ—ï¸ **Latest News Summary on: {query}**

You are a smart and concise AI assistant summarizing breaking or trending news. Based on the topic, generate a short, factual overview in 3 to 5 bullet points.

ğŸ¯ Format: Bullet points only  
âœ… Tone: Crisp, neutral, informative  
ğŸš« Avoid: Repetition, filler, and vague language

Provide the summary below:

- 
"""

# âœ… Creating a prompt object with input variable 'query'
prompt = PromptTemplate(template=initial_template, input_variables=["query"])

# âœ… Setting up LangChain LLMChain to connect the prompt and Groq LLM
llm_chain = LLMChain(prompt=prompt, llm=llm)

# âœ… Initializing NewsAPI client to fetch real-time news articles
newsapi = NewsApiClient(api_key=NEWS_API_KEY)

def get_news_articles(query):
    # âœ… Using NewsAPI to fetch relevant news articles based on user input
    articles = newsapi.get_everything(q=query, language='en', sort_by='relevancy')
    return articles['articles']

def summarize_articles(articles):
    # âœ… Extracting article descriptions (if present) to create input for summarization
    summaries = [article['description'] or '' for article in articles if article.get('description')]
    return ' '.join(summaries)

def get_summary(query):
    # âœ… Main controller: fetches news and feeds them into the LLM for summarization
    articles = get_news_articles(query)
    summaries = summarize_articles(articles)
    return llm_chain.run(query=query, summaries=summaries)

# âœ… Enhanced Prompt Template for smarter summarization using actual content
# This helps the LLM generate more context-aware, high-quality summaries
enhanced_template = """
You are an intelligent AI news summarizer. Based on the given user query and the collected summaries from multiple articles,
generate a clear, unbiased, and informative overview of the topic. Ensure the summary is digestible and reflects the key points covered by the news.

Query: {query}
Summaries: {summaries}
"""

# âœ… Rebuilding the LLMChain with improved prompt and both inputs: query + summaries
enhanced_prompt = PromptTemplate(template=enhanced_template, input_variables=["query", "summaries"])
llm_chain = LLMChain(prompt=enhanced_prompt, llm=llm)


# âœ… Outcome:
# Iâ€™ve now fully connected LangChain to Groqâ€™s LLM and NewsAPI.
# My tool can now fetch and summarize real-time news on any topic â€” politics, tech, finance, sports, and more â€”
# using smart prompt templates and chains for accurate, readable summaries.
